"""
External Reconnaissance service plugin

Generates tasks for OSINT and external recon including:
- GitHub leaked secrets discovery (trufflehog, gitleaks)
- Wide source code search (Sourcegraph, Github Search)
- ASN discovery and IP range enumeration
- Subdomain enumeration (amass, subfinder, assetfinder)
- Domain discovery (WHOIS, certificate transparency)
- Credential leak searches
- Public cloud asset discovery

Extracted from HackTricks: external-recon-methodology/
Generated by: CrackPot v1.0
"""

from typing import Dict, Any, List
from .base import ServicePlugin
from .registry import ServiceRegistry


@ServiceRegistry.register
class ExternalReconPlugin(ServicePlugin):
    """External reconnaissance and OSINT enumeration plugin"""

    @property
    def name(self) -> str:
        return "external-recon"

    @property
    def default_ports(self) -> List[int]:
        return []  # Not port-specific, applies to target discovery phase

    @property
    def service_names(self) -> List[str]:
        return ['recon', 'osint', 'external-recon']

    def detect(self, port_info: Dict[str, Any]) -> bool:
        """Detect if external recon should be triggered - usually manually invoked"""
        # This plugin is typically manually triggered for a target domain/company
        # Not automatically detected from port scans
        return False

    def get_task_tree(self, target: str, port: int, service_info: Dict[str, Any]) -> Dict[str, Any]:
        """
        Generate external reconnaissance task tree

        Args:
            target: Domain name or company name (e.g., "example.com" or "Example Corp")
            port: Not used for external recon (pass 0)
            service_info: Optional metadata (organization name, etc.)
        """
        org_name = service_info.get('organization', target)

        tasks = {
            'id': f'external-recon-{target.replace(".", "-")}',
            'name': f'External Reconnaissance: {target}',
            'type': 'parent',
            'children': []
        }

        # ===== PHASE 1: ASSET DISCOVERY =====
        asset_discovery = {
            'id': f'asset-discovery-{target.replace(".", "-")}',
            'name': 'Asset Discovery',
            'type': 'parent',
            'children': []
        }

        # 1.1: ASN Discovery
        asset_discovery['children'].append({
            'id': f'asn-discovery-{target.replace(".", "-")}',
            'name': 'ASN & IP Range Discovery',
            'type': 'command',
            'metadata': {
                'command': f'amass intel -org "{org_name}"',
                'description': 'Discover Autonomous System Numbers and IP ranges owned by organization',
                'tags': ['OSCP:HIGH', 'RECON', 'QUICK_WIN'],
                'flag_explanations': {
                    'intel': 'Intelligence gathering mode (ASN discovery)',
                    '-org': 'Search by organization name to find ASNs'
                },
                'success_indicators': [
                    'ASN numbers discovered',
                    'IP ranges identified',
                    'Network blocks enumerated'
                ],
                'failure_indicators': [
                    'No ASNs found (small organization)',
                    'Rate limited by BGP database'
                ],
                'next_steps': [
                    'Use discovered ASNs with amass: amass intel -asn <ASN>',
                    'Query IP ranges: https://bgp.he.net/',
                    'Check regional registries (ARIN, RIPE, APNIC)',
                    'Scan discovered IP ranges with nmap'
                ],
                'alternatives': [
                    'Manual: https://bgp.he.net/ search by company name',
                    'Manual: whois -h whois.radb.net <domain>',
                    'bbot -t example.com -f subdomain-enum (aggregates ASNs)',
                    'http://asnlookup.com/ (free API available)'
                ],
                'notes': 'ASN discovery reveals infrastructure footprint - critical for scoping'
            }
        })

        # 1.2: Reverse WHOIS
        asset_discovery['children'].append({
            'id': f'reverse-whois-{target.replace(".", "-")}',
            'name': 'Reverse WHOIS Discovery',
            'type': 'manual',
            'metadata': {
                'description': 'Find related domains via WHOIS email, organization name, registrant info',
                'tags': ['OSCP:MEDIUM', 'RECON', 'MANUAL'],
                'alternatives': [
                    'https://viewdns.info/reversewhois/ (FREE)',
                    'https://domaineye.com/reverse-whois (FREE)',
                    'https://www.reversewhois.io/ (FREE)',
                    'https://www.whoxy.com/ (FREE web)',
                    'amass intel -d example.com -whois (automated)',
                    'DomLink tool (requires whoxy API key)'
                ],
                'success_indicators': [
                    'Additional domains found with same registrant',
                    'Sister companies discovered',
                    'Acquisitions identified'
                ],
                'next_steps': [
                    'Add discovered domains to scope',
                    'Repeat reverse WHOIS on new findings (recursive)',
                    'Build domain relationship map'
                ],
                'notes': 'Recursive approach: each new domain = new WHOIS lookup opportunity'
            }
        })

        # 1.3: Tracker-based Discovery
        asset_discovery['children'].append({
            'id': f'tracker-discovery-{target.replace(".", "-")}',
            'name': 'Tracker-based Domain Discovery',
            'type': 'manual',
            'metadata': {
                'description': 'Find related domains via shared Google Analytics, Adsense IDs, tracking codes',
                'tags': ['OSCP:LOW', 'RECON', 'MANUAL'],
                'alternatives': [
                    'Udon: https://github.com/dhn/udon',
                    'BuiltWith: https://builtwith.com',
                    'Sitesleuth: https://www.sitesleuth.io',
                    'Publicwww: https://publicwww.com (search by tracker ID)',
                    'SpyOnWeb: http://spyonweb.com'
                ],
                'success_indicators': [
                    'Multiple sites sharing same Google Analytics ID',
                    'Related properties under same management'
                ],
                'notes': 'Same tracker ID = likely same team/organization'
            }
        })

        tasks['children'].append(asset_discovery)

        # ===== PHASE 2: SUBDOMAIN ENUMERATION =====
        subdomain_enum = {
            'id': f'subdomain-enum-{target.replace(".", "-")}',
            'name': 'Subdomain Enumeration',
            'type': 'parent',
            'children': []
        }

        # 2.1: Passive Subdomain Discovery (BBOT)
        subdomain_enum['children'].append({
            'id': f'bbot-subdomain-{target.replace(".", "-")}',
            'name': 'BBOT Passive Subdomain Enumeration',
            'type': 'command',
            'metadata': {
                'command': f'bbot -t {target} -f subdomain-enum -rf passive -n recon_{target.replace(".", "_")} -o /tmp',
                'description': 'Comprehensive passive subdomain enumeration using multiple OSINT sources',
                'tags': ['OSCP:HIGH', 'AUTOMATED', 'STEALTH'],
                'flag_explanations': {
                    '-t': 'Target domain',
                    '-f subdomain-enum': 'Use subdomain enumeration flag preset',
                    '-rf passive': 'Passive mode only (no active scanning)',
                    '-n': 'Scan name for output files',
                    '-o': 'Output directory'
                },
                'estimated_time': '5-10 minutes',
                'success_indicators': [
                    'Subdomains discovered from certificate transparency',
                    'DNS records from passive sources',
                    'ASN summary at end of scan'
                ],
                'alternatives': [
                    f'subfinder -d {target} -silent',
                    f'amass enum -passive -d {target}',
                    f'assetfinder --subs-only {target}'
                ],
                'next_steps': [
                    'Verify discovered subdomains are live (httpx)',
                    'Port scan interesting subdomains',
                    'Check for subdomain takeovers'
                ],
                'notes': 'BBOT aggregates 20+ sources automatically, including crt.sh, certificate transparency logs'
            }
        })

        # 2.2: Amass Active Enumeration
        subdomain_enum['children'].append({
            'id': f'amass-enum-{target.replace(".", "-")}',
            'name': 'Amass Active Subdomain Enumeration',
            'type': 'command',
            'metadata': {
                'command': f'amass enum -active -d {target} -o amass_{target.replace(".", "_")}.txt',
                'description': 'Active subdomain enumeration with DNS zone transfers, brute-forcing',
                'tags': ['OSCP:HIGH', 'AUTOMATED', 'NOISY'],
                'flag_explanations': {
                    'enum': 'Enumeration mode',
                    '-active': 'Enable active techniques (zone transfers, cert grabbing, more queries)',
                    '-d': 'Target domain',
                    '-o': 'Output file'
                },
                'estimated_time': '10-30 minutes',
                'success_indicators': [
                    'Subdomains not found by passive methods',
                    'Zone transfer successful (VERY rare but high value)',
                    'Certificate-based discoveries'
                ],
                'failure_indicators': [
                    'Rate limited by DNS servers',
                    'Firewall blocking enumeration'
                ],
                'alternatives': [
                    f'amass enum -d {target} (passive only)',
                    f'subfinder -d {target}',
                    f'findomain -t {target}'
                ],
                'notes': 'Active mode is noisy - use in authorized engagements only'
            }
        })

        # 2.3: DNS Brute-forcing
        subdomain_enum['children'].append({
            'id': f'dns-bruteforce-{target.replace(".", "-")}',
            'name': 'DNS Subdomain Brute-force',
            'type': 'command',
            'metadata': {
                'command': f'puredns bruteforce /usr/share/wordlists/dnsmap.txt {target} -r /tmp/resolvers.txt -w puredns_{target.replace(".", "_")}.txt',
                'description': 'Brute-force subdomains using high-quality wordlist and fast resolvers',
                'tags': ['OSCP:MEDIUM', 'BRUTE_FORCE', 'NOISY'],
                'flag_explanations': {
                    'bruteforce': 'Brute-force mode',
                    '/usr/share/wordlists/dnsmap.txt': 'Subdomain wordlist (try also: all.txt from assetnote)',
                    '-r': 'Trusted DNS resolvers file (critical for speed)',
                    '-w': 'Output file for valid subdomains'
                },
                'estimated_time': '30+ minutes (depends on wordlist size)',
                'success_indicators': [
                    'Valid subdomains not in public records',
                    'Internal naming conventions discovered'
                ],
                'alternatives': [
                    f'shuffledns -d {target} -list subdomains.txt -r resolvers.txt',
                    f'gobuster dns -d {target} -t 50 -w subdomains.txt',
                    f'massdns -r resolvers.txt -t A -o S wordlist.txt',
                    'Better wordlists: https://wordlists-cdn.assetnote.io/data/manual/best-dns-wordlist.txt'
                ],
                'notes': 'Generate resolvers: https://raw.githubusercontent.com/trickest/resolvers/main/resolvers-trusted.txt'
            }
        })

        # 2.4: Certificate Transparency
        subdomain_enum['children'].append({
            'id': f'crt-sh-{target.replace(".", "-")}',
            'name': 'Certificate Transparency Logs',
            'type': 'command',
            'metadata': {
                'command': f'curl -s "https://crt.sh/?q=%25.{target}" | grep -oE "[.a-zA-Z0-9-]+\\.{target}" | sort -u',
                'description': 'Query certificate transparency logs for subdomains from SSL certificates',
                'tags': ['OSCP:HIGH', 'QUICK_WIN', 'MANUAL', 'STEALTH'],
                'flag_explanations': {
                    'crt.sh': 'Free certificate transparency log search engine',
                    '%25': 'URL-encoded wildcard (*) to match all subdomains',
                    'grep -oE': 'Extract only subdomain patterns'
                },
                'estimated_time': '< 1 minute',
                'success_indicators': [
                    'Subdomains from historical certificates',
                    'Wildcards revealing naming patterns'
                ],
                'alternatives': [
                    'Manual: https://crt.sh/?q=%25.example.com',
                    'censys: export CENSYS_API_ID=...; censys-subdomain-finder.py example.com',
                    'Via curl: curl -s https://crt.sh/?q=%.example.com&output=json | jq'
                ],
                'next_steps': [
                    'Check for expired/revoked cert subdomains (may still resolve)',
                    'Look for wildcard patterns to generate more subdomains'
                ],
                'notes': 'CT logs are gold mine - every SSL cert issued is logged publicly'
            }
        })

        tasks['children'].append(subdomain_enum)

        # ===== PHASE 3: SECRET LEAKS =====
        secret_leaks = {
            'id': f'secret-leaks-{target.replace(".", "-")}',
            'name': 'Secret & Credential Leaks',
            'type': 'parent',
            'children': []
        }

        # 3.1: GitHub Secret Scanning
        secret_leaks['children'].append({
            'id': f'github-secrets-{target.replace(".", "-")}',
            'name': 'GitHub Leaked Secrets (TruffleHog)',
            'type': 'command',
            'metadata': {
                'command': f'trufflehog github --org {org_name} --json > trufflehog_{target.replace(".", "_")}.json',
                'description': 'Scan GitHub organization repositories for leaked secrets, keys, tokens',
                'tags': ['OSCP:HIGH', 'RESEARCH', 'QUICK_WIN'],
                'flag_explanations': {
                    'github': 'Scan GitHub repositories',
                    '--org': 'Target organization name on GitHub',
                    '--json': 'Output in JSON format for parsing'
                },
                'estimated_time': '2-10 minutes (depends on repo count)',
                'success_indicators': [
                    'API keys discovered in commit history',
                    'Hardcoded passwords found',
                    'AWS credentials, tokens exposed'
                ],
                'failure_indicators': [
                    'No public repositories',
                    'Organization name not found on GitHub',
                    'Rate limited (use --token with GitHub PAT)'
                ],
                'alternatives': [
                    f'gitleaks detect --source /path/to/repo --verbose',
                    f'noseyparker scan github --organization {org_name}',
                    'GitGuardian: ggshield secret scan repo <repo_url>',
                    'Manual: GitHub search org:ORGNAME "password"',
                    'Manual: GitHub search org:ORGNAME extension:env',
                    'Manual: GitHub search org:ORGNAME filename:.bash_history'
                ],
                'next_steps': [
                    'Test discovered credentials immediately',
                    'Check if keys are still valid',
                    'Search for same patterns across all repos',
                    'Download repos with Leakos: https://github.com/carlospolop/Leakos'
                ],
                'notes': 'Even deleted commits are in Git history - use tools that scan entire history'
            }
        })

        # 3.2: GitHub Dorking
        secret_leaks['children'].append({
            'id': f'github-dorks-{target.replace(".", "-")}',
            'name': 'GitHub Dork Search',
            'type': 'manual',
            'metadata': {
                'description': 'Use GitHub advanced search with dorks to find sensitive files and credentials',
                'tags': ['OSCP:HIGH', 'MANUAL', 'RESEARCH'],
                'alternatives': [
                    f'Manual: org:{org_name} "AWS_ACCESS_KEY_ID"',
                    f'Manual: org:{org_name} filename:.env',
                    f'Manual: org:{org_name} extension:pem private',
                    f'Manual: org:{org_name} filename:wp-config.php',
                    f'Manual: org:{org_name} filename:id_rsa',
                    f'Manual: user:{org_name} password',
                    'GitDorker: https://github.com/obheda12/GitDorker (automated)',
                    'TechGaun dorks list: https://github.com/techgaun/github-dorks'
                ],
                'success_indicators': [
                    'Configuration files with credentials',
                    'Private keys exposed',
                    'Database connection strings',
                    'API tokens in code'
                ],
                'next_steps': [
                    'Clone interesting repos for deeper analysis',
                    'Check git log -p for deleted secrets',
                    'Search across all branches (secrets may be in feature branches)'
                ],
                'notes': 'GitHub search syntax: https://docs.github.com/en/search-github/searching-on-github/searching-code'
            }
        })

        # 3.3: Source Code Search Engines
        secret_leaks['children'].append({
            'id': f'source-search-{target.replace(".", "-")}',
            'name': 'Wide Source Code Search',
            'type': 'manual',
            'metadata': {
                'description': 'Search across millions of repos using Sourcegraph, Github Code Search, SearchCode',
                'tags': ['OSCP:MEDIUM', 'RESEARCH', 'MANUAL'],
                'alternatives': [
                    f'Sourcegraph: https://sourcegraph.com/search?q={target}+password',
                    f'GitHub Code Search: https://cs.github.com/ - search: {target} api_key',
                    f'SearchCode: https://searchcode.com/?q={target}',
                    f'Gitlab Advanced Search: Search repos for {target} credentials'
                ],
                'success_indicators': [
                    'Hardcoded credentials in open source projects',
                    'Configuration examples with real data',
                    'API usage examples with valid tokens'
                ],
                'notes': 'These search engines index public code across multiple platforms - cast wide net'
            }
        })

        # 3.4: Credential Leak Databases
        secret_leaks['children'].append({
            'id': f'cred-leaks-{target.replace(".", "-")}',
            'name': 'Credential Leak Search',
            'type': 'manual',
            'metadata': {
                'description': 'Search breach databases for leaked credentials of target domain emails',
                'tags': ['OSCP:HIGH', 'RESEARCH', 'MANUAL'],
                'alternatives': [
                    f'leak-lookup.com - search: @{target}',
                    f'dehashed.com - search: domain:{target}',
                    'haveibeenpwned.com/DomainSearch (requires API key)',
                    'Manual: Search paste sites with Pastos tool'
                ],
                'success_indicators': [
                    'Valid credentials from breaches',
                    'Password patterns identified',
                    'Reused passwords across accounts'
                ],
                'next_steps': [
                    'Test discovered credentials on target services',
                    'Build custom wordlist from leaked passwords',
                    'Check password reuse across multiple platforms'
                ],
                'notes': 'Leaked credentials are QUICK WINS - test immediately on VPN, email, admin panels'
            }
        })

        tasks['children'].append(secret_leaks)

        # ===== PHASE 4: CLOUD ASSETS =====
        cloud_assets = {
            'id': f'cloud-assets-{target.replace(".", "-")}',
            'name': 'Public Cloud Asset Discovery',
            'type': 'parent',
            'children': []
        }

        # 4.1: S3 Bucket Enumeration
        cloud_assets['children'].append({
            'id': f's3-buckets-{target.replace(".", "-")}',
            'name': 'AWS S3 Bucket Discovery',
            'type': 'command',
            'metadata': {
                'command': f'cloud_enum -k {target}',
                'description': 'Enumerate AWS S3 buckets, Azure storage, Google Cloud storage using target keywords',
                'tags': ['OSCP:MEDIUM', 'AUTOMATED', 'QUICK_WIN'],
                'flag_explanations': {
                    '-k': 'Keyword to generate bucket name permutations',
                    'cloud_enum': 'Checks AWS, Azure, GCP for publicly accessible storage'
                },
                'estimated_time': '5-15 minutes',
                'success_indicators': [
                    'Publicly accessible S3 buckets found',
                    'Open Azure blob storage discovered',
                    'Listable/writable cloud storage'
                ],
                'alternatives': [
                    f'S3Scanner -l bucket_wordlist.txt',
                    f'CloudScraper -u {target}',
                    'Manual: aws s3 ls s3://{target} --no-sign-request',
                    'Manual: curl http://{target}.s3.amazonaws.com/',
                    'Generate permutations: altdns/goaltdns then check S3'
                ],
                'next_steps': [
                    'List bucket contents if accessible',
                    'Check for write permissions (upload test file)',
                    'Download sensitive files',
                    'Look for subdomain takeover via S3'
                ],
                'notes': 'Generate bucket names from: company name, subdomains, common words (backup, dev, staging, prod)'
            }
        })

        tasks['children'].append(cloud_assets)

        # ===== PHASE 5: EMAIL & EMPLOYEES =====
        email_enum = {
            'id': f'email-enum-{target.replace(".", "-")}',
            'name': 'Email & Employee Discovery',
            'type': 'parent',
            'children': []
        }

        # 5.1: Email Harvesting
        email_enum['children'].append({
            'id': f'email-harvest-{target.replace(".", "-")}',
            'name': 'Email Address Harvesting',
            'type': 'command',
            'metadata': {
                'command': f'theHarvester -d {target} -b "google,bing,linkedin,hunter" -l 500',
                'description': 'Harvest email addresses from search engines, LinkedIn, Hunter.io',
                'tags': ['OSCP:HIGH', 'RECON', 'QUICK_WIN'],
                'flag_explanations': {
                    '-d': 'Target domain',
                    '-b': 'Data sources (comma-separated)',
                    '-l': 'Limit results per source'
                },
                'estimated_time': '2-5 minutes',
                'success_indicators': [
                    'Employee email addresses discovered',
                    'Naming convention identified (first.last@, flast@)',
                    'Department emails found'
                ],
                'alternatives': [
                    'Hunter.io API (free tier): https://hunter.io/',
                    'Snov.io API: https://app.snov.io/',
                    'LinkedIn scraping (manual)',
                    'Google dorking: site:linkedin.com "at {target}"'
                ],
                'next_steps': [
                    'Build username list for password spraying',
                    'Identify high-value targets (admins, IT staff)',
                    'Craft phishing campaigns',
                    'Check emails against breach databases'
                ],
                'notes': 'Email format reveals naming convention - use to generate more usernames'
            }
        })

        tasks['children'].append(email_enum)

        return tasks
